{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech\r\n",
        "\r\n",
        "Wir erwarten immer öfter, mit KI-Systemen (Künstliche Intelligenz) kommunizieren zu können, indem wir mit ihnen sprechen, und erwarten oft auch eine gesprochene Antwort.\r\n",
        "\r\n",
        "![Ein sprechender Roboter](./images/speech.jpg)\r\n",
        "\r\n",
        "*Spracherkennung* (ein KI-System, das gesprochene Sprache interpretiert) und *Sprachsynthese* (ein KI-System, das eine gesprochene Antwort generiert) sind die wichtigsten Komponenten einer KI-Lösung mit Sprachunterstützung.\r\n",
        "\r\n",
        "## Erstellen einer Cognitive Services-Ressource\r\n",
        "\r\n",
        "Um eine Software zu erstellen, die gesprochene Sprache interpretiert und verbal antwortet, können Sie den Cognitive Service **Speech** verwenden, der einfache Methoden zum Transkribieren von gesprochener Sprache zu Text und umgekehrt bereitstellt.\r\n",
        "\r\n",
        "Falls noch nicht geschehen, führen Sie die folgenden Schritte aus, um eine **Cognitive Services**-Ressource in Ihrem Azure-Abonnement zu erstellen:\r\n",
        "\r\n",
        "> **Hinweis**: Falls Sie bereits eine Cognitive Services-Ressource haben, können Sie die entsprechende **Schnellstart**-Seite im Azure-Portal öffnen und den Schlüssel und den Endpunkt der Ressource unten in die Zelle kopieren. Führen Sie andernfalls die folgenden Schritte aus, um eine Ressource zu erstellen.\r\n",
        "\r\n",
        "1. Öffnen Sie das Azure-Portal unter „https://portal.azure.com“ in einer neuen Browserregisterkarte, und melden Sie sich mit Ihrem Microsoft-Konto an.\r\n",
        "2. Klicken Sie auf die Schaltfläche **&#65291;Ressource erstellen**, suchen Sie nach *Cognitive Services*, und erstellen Sie eine **Cognitive Services**-Ressource mit den folgenden Einstellungen:\r\n",
        "    – **Abonnement**: *Ihr Azure-Abonnement*\r\n",
        "    – **Ressourcengruppe**: *Wählen Sie eine Ressourcengruppe aus, oder erstellen Sie eine Ressourcengruppe mit einem eindeutigen Namen.*\r\n",
        "    – **Region**: *Wählen Sie eine verfügbare Region aus*:\r\n",
        "    – **Name**: *Geben Sie einen eindeutigen Namen ein.*\r\n",
        "    – **Tarif**: S0\r\n",
        "    – **Ich bestätige, dass ich die Hinweise gelesen und verstanden habe**: Ausgewählt\r\n",
        "3. Warten Sie, bis die Bereitstellung abgeschlossen ist. Öffnen Sie anschließend Ihre Cognitive Services-Ressource, und klicken Sie auf der Seite **Übersicht** auf den Link zur Schlüsselverwaltung für den Dienst. Sie benötigen den Schlüssel und den Speicherort, um sich aus Clientanwendungen heraus mit Ihrer Cognitive Services-Ressource zu verbinden.\r\n",
        "\r\n",
        "### Abrufen des Schlüssels und des Speicherorts für Ihre Cognitive Services-Ressource\r\n",
        "\r\n",
        "Um Ihre Cognitive Services-Ressource verwenden zu können, benötigen Clientanwendungen deren Authentifizierungsschlüssel und Speicherort:\r\n",
        "\r\n",
        "1. Kopieren Sie im Azure-Portal auf der Seite **Schlüssel und Endpunkt** für Ihre Cognitive Service-Ressource den **Schlüssel1** für Ihre Ressource, und fügen Sie ihn im unten stehenden Code anstelle von **YOUR_COG_KEY** ein.\r\n",
        "2. Kopieren Sie den **Speicherort** für Ihre Ressource, und fügen Sie ihn unten im Code anstelle von **YOUR_COG_LOCATION** ein.\r\n",
        ">**Hinweis**: Bleiben Sie auf der Seite **Schlüssel und Endpunkt**, und kopieren Sie den **Speicherort** von dieser Seite (Beispiel: _westus_). Fügen Sie KEINE Leerzeichen zwischen den Wörtern im Feld „Speicherort“ ein. \r\n",
        "3. Führen Sie den folgenden Code aus, indem Sie links neben der Zelle auf die Schaltfläche **Zelle ausführen** (&#9655) klicken."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spracherkennung\r\n",
        "\r\n",
        "Angenommen, Sie möchten ein Gebäudeautomatisierungssystem entwickeln, das Sprachbefehle wie etwa „Licht einschalten“ oder „Licht ausschalten“ erkennt. Ihre Anwendung muss in der Lage sein, audiobasierte Eingaben (Ihre Sprachbefehle) zu interpretieren, indem sie sie zu Text transkribiert, der anschließend gelesen und analysiert werden kann.\r\n",
        "\r\n",
        "Jetzt können Sie damit anfangen, Spracheingaben zu transkribieren. Die Eingabe kann entweder von einem **Mikrofon** oder aus einer **Audiodatei** stammen. \r\n",
        "\r\n",
        "### Spracherkennung mit einem Mikrofon\r\n",
        "\r\n",
        "Probieren sie zuerst die Eingabe mit einem Mikrofon aus. Führen Sie die folgende Zelle aus, und sprechen Sie **sofort** den Befehl **„Licht einschalten“** in Ihr Mikrofon. Die Sprache-in-Text-Funktion des Speech-Diensts transkribiert die Audioeingabe. Ihre gesprochenen Wörter sollten als Text ausgegeben werden.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Konfigurieren der Spracherkennung\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "\n",
        "# Kursteilnehmer auffordern, „Licht einschalten“ zu sagen \r\n",
        "speech_recognizer = SpeechRecognizer(speech_config)\n",
        "\n",
        "# Transkribieren der Sprache mit einem einzigen synchronen Aufruf\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "print(speech.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695250434
        }
      }
    },
    {
      "source": [
        "### (!) Überprüfung\r\n",
        "\r\n",
        "Konnten Sie die Zelle ausführen und Ihre Spracheingabe in Text umwandeln? Falls die vorherige Zelle keine Textausgabe liefert (Beispielausgabe: _Licht einschalten._), führen Sie die Zelle erneut aus, und sprechen Sie **sofort** den Befehl „Licht einschalten“ in Ihr Mikrofon.\r\n",
        "\r\n",
        "### Spracherkennung mit einer Audiodatei\r\n",
        "\r\n",
        "Falls die vorherige Zelle keine Textausgabe liefert, ist Ihr Mikrofon möglicherweise nicht für die Spracheingabe eingerichtet. Führen Sie stattdessen die folgende Zelle aus, um den Spracherkennungsdienst mit einer **Audiodatei** anstelle der **Mikrofoneingabe** zu testen. \r\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Abrufen des Sprachbefehls aus einer Audiodatei\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Konfigurieren der Spracherkennung\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Transkribieren der Sprache mit einem einzigen synchronen Aufruf\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Wiedergeben von Audio und Anzeigen des transkribierten Texts\r\n",
        "playsound(audio_file)\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sprachsynthese\r\n",
        "\r\n",
        "Sie haben also gesehen, wie der Speech-Dienst gesprochene Wörter zu Text transkribieren kann, aber funktioniert dies auch umgekehrt? Wie können Sie Text zu Sprache konvertieren?\r\n",
        "\r\n",
        "Angenommen, Ihr Gebäudeautomatisierungssystem hat einen Befehl erhalten, das Licht einzuschalten. Eine passende Antwort wäre beispielsweise eine verbale Bestätigung des Befehls (und natürlich die Ausführung des Befehls)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Aussprechen von Text\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Konfigurieren der Sprachsynthese\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Transkribieren von Text zu Sprache\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Anzeigen eines passenden Bilds \r\n",
        "file_name = response_text + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ändern Sie die Variable **response_text** zu *Licht wird ausgeschaltet.* (inklusive Punkt am Ende), und führen Sie die Zelle erneut aus, um das Ergebnis zu hören.\r\n",
        "\r\n",
        "## Weitere Informationen\r\n",
        "\r\n",
        "In diesem Notebook haben Sie ein sehr einfaches Beispiel für die Nutzung des Cognitive Service „Speech“ gesehen. Weitere Informationen zu den Funktionen [Sprache-in-Text](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) und [Text-zu-Sprache](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) finden Sie in der Dokumentation für den Speech-Dienst."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.5-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      }
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}